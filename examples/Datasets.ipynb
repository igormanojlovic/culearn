{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Datasets\n",
    "\n",
    "This notebook shows how to prepare and explore existing datasets with smart meter and weather data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Preparing data sources\n",
    "\n",
    "Cumulant Learning requires an instance of the `culearn.base.PredictionDataset` class to represent a dataset with X and Y variables. You can either create this instance directly or you can use existing implementations of the `culearn.data.DataSource` class that will create some predefined datasets for you:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from culearn.data import *\n",
    "\n",
    "sources = [\n",
    "    LCL('../data/LCL'),\n",
    "    REFIT('../data/REFIT'),\n",
    "    SGSC('../data/SGSC'),\n",
    "    UMass('../data/UMass')\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The existing data sources will create datasets with weather data as X variables and smart meter data as Y variables. `LCL`, `REFIT`, and `SGSC` use [meteostat.net](https://meteostat.net/) as default weather data source, while `UMass` uses the weather data provided alongside the smart meter data. Alternatively, you can replace [meteostat.net](https://meteostat.net/) with [worldweatheronline.com](https://www.worldweatheronline.com/) like this:\n",
    "```\n",
    "api_key='<YOUR_API_KEY>'\n",
    "sources = [\n",
    "    LCL('../data/LCL', WorldWeather, api_key=api_key),\n",
    "    REFIT('../data/REFIT', WorldWeather, api_key=api_key),\n",
    "    SGSC('../data/SGSC', WorldWeather, api_key=api_key),\n",
    "    UMass('../data/UMass')\n",
    "]\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "If neither of these weather data providers are suitable to your use case you can implement your own subclass of the `culearn.data.Weather` class and pass it to the data sources instead."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading datasets\n",
    "\n",
    "To create datasets from a data source you just need to call the `.dataset()` function. This will download smart meter and weather data for load forecasting from external data sources, unzip the data files, and split the larger CSV files with multiple time series into smaller ones with individual time series to support parallel processing. This might take a while at first, but will make the rest of the process much faster. However, there is a small exception: `REFIT` currently does not support automatic download, so it will raise an exception instructing you to download the data manually - you will be able to create the dataset after that."
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = {}\n",
    "for source in sources:\n",
    "    dataset_name = type(source).__name__\n",
    "    print(f'Preparing {dataset_name} data.')\n",
    "    datasets[dataset_name] = source.dataset()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exploring data\n",
    "\n",
    "Each `culearn.base.PredictionDataset` contains X variables in one `pandas.DataFrame` instance and Y variables in a collection of `culearn.csv.TimeSeriesCSV` instances. For each Y variable, the Y values can be accessed via `.stream()` and `.series()` functions. The `.stream()` function iteratively returns Y values as a collection of `culearn.base.TimeSeriesTuple` instances (for stream processing), while the `.series()` function monolithically returns Y values as one `pandas.Series` instance (for batch processing)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for dataset_name, dataset in datasets.items():\n",
    "    print(dataset_name)\n",
    "\n",
    "    print(f'All {len(dataset.x.columns)} X variables:')\n",
    "    display(dataset.x)\n",
    "\n",
    "    print(f'1 of {len(dataset.y)} Y variables:')\n",
    "    for y in dataset.y:\n",
    "        print(f'Y tuple:')\n",
    "        for y_tuple in y.stream():\n",
    "            print(y_tuple)\n",
    "            break\n",
    "\n",
    "        print(f'Y series:')\n",
    "        display(y.series().to_frame())\n",
    "        break"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
